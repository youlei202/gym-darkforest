{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "from tensorforce.agents import PPOAgent\n",
    "from tensorforce.execution import Runner\n",
    "from tensorforce.contrib.openai_gym import OpenAIGym\n",
    " \n",
    "import gym_darkforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = OpenAIGym('darkforest-v0') \n",
    "network_spec = [\n",
    "     #dict(type='embedding', indices=100, size=32),\n",
    "     dict(type='dense', size=32, activation='tanh'),\n",
    "     dict(type='dense', size=32, activation='tanh')\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent = PPOAgent(\n",
    "     states_spec=env.states,\n",
    "     actions_spec=env.actions,\n",
    "     network_spec=network_spec,\n",
    "     batch_size=4096,\n",
    "     # Agent\n",
    "     states_preprocessing_spec=None,\n",
    "     explorations_spec=None,\n",
    "     reward_preprocessing_spec=None,\n",
    "     # BatchAgent\n",
    "     keep_last_timestep=True,\n",
    "     # PPOAgent\n",
    "     step_optimizer=dict(\n",
    "         type='adam',\n",
    "         learning_rate=1e-3\n",
    "     ),\n",
    "     optimization_steps=10,\n",
    "     # Model\n",
    "     scope='ppo',\n",
    "     discount=0.99,\n",
    "     # DistributionModel\n",
    "     distributions_spec=None,\n",
    "     entropy_regularization=0.01,\n",
    "     # PGModel\n",
    "     baseline_mode=None,\n",
    "     baseline=None,\n",
    "     baseline_optimizer=None,\n",
    "     gae_lambda=None,\n",
    "     # PGLRModel\n",
    "     likelihood_ratio_clipping=0.2,\n",
    "     summary_spec=None,\n",
    "     distributed_spec=None\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runner = Runner(agent=agent, environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def episode_finished(r):\n",
    "    print(\"Finished episode {ep} after {ts} timesteps (reward: {reward})\".format(ep=r.episode, ts=r.episode_timestep,\n",
    "                                                                                  reward=r.episode_rewards[-1]))\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode 1 after 24 timesteps (reward: -1)\n",
      "Finished episode 2 after 24 timesteps (reward: -1)\n",
      "Finished episode 3 after 24 timesteps (reward: -1)\n",
      "Finished episode 4 after 24 timesteps (reward: -1)\n",
      "Finished episode 5 after 24 timesteps (reward: -1)\n",
      "Finished episode 6 after 24 timesteps (reward: -1)\n",
      "Finished episode 7 after 24 timesteps (reward: -1)\n",
      "Finished episode 8 after 24 timesteps (reward: -1)\n",
      "Finished episode 9 after 24 timesteps (reward: -1)\n",
      "Finished episode 10 after 24 timesteps (reward: -1)\n",
      "Finished episode 11 after 24 timesteps (reward: -1)\n",
      "Finished episode 12 after 24 timesteps (reward: -1)\n",
      "Finished episode 13 after 24 timesteps (reward: -1)\n",
      "Finished episode 14 after 24 timesteps (reward: -1)\n",
      "Finished episode 15 after 24 timesteps (reward: -1)\n",
      "Finished episode 16 after 24 timesteps (reward: -1)\n",
      "Finished episode 17 after 24 timesteps (reward: -1)\n",
      "Finished episode 18 after 24 timesteps (reward: -1)\n",
      "Finished episode 19 after 24 timesteps (reward: -1)\n",
      "Finished episode 20 after 24 timesteps (reward: -1)\n",
      "Finished episode 21 after 24 timesteps (reward: -1)\n",
      "Finished episode 22 after 24 timesteps (reward: -1)\n",
      "Finished episode 23 after 24 timesteps (reward: -1)\n",
      "Finished episode 24 after 24 timesteps (reward: -1)\n",
      "Finished episode 25 after 24 timesteps (reward: -1)\n",
      "Finished episode 26 after 24 timesteps (reward: -1)\n",
      "Finished episode 27 after 24 timesteps (reward: -1)\n",
      "Finished episode 28 after 24 timesteps (reward: -1)\n",
      "Finished episode 29 after 24 timesteps (reward: -1)\n",
      "Finished episode 30 after 24 timesteps (reward: -1)\n",
      "Finished episode 31 after 24 timesteps (reward: -1)\n",
      "Finished episode 32 after 24 timesteps (reward: -1)\n",
      "Finished episode 33 after 24 timesteps (reward: -1)\n",
      "Finished episode 34 after 24 timesteps (reward: -1)\n",
      "Finished episode 35 after 24 timesteps (reward: -1)\n",
      "Finished episode 36 after 24 timesteps (reward: -1)\n",
      "Finished episode 37 after 24 timesteps (reward: -1)\n",
      "Finished episode 38 after 24 timesteps (reward: -1)\n",
      "Finished episode 39 after 24 timesteps (reward: -1)\n",
      "Finished episode 40 after 24 timesteps (reward: -1)\n",
      "Finished episode 41 after 24 timesteps (reward: -1)\n",
      "Finished episode 42 after 24 timesteps (reward: -1)\n",
      "Finished episode 43 after 24 timesteps (reward: -1)\n",
      "Finished episode 44 after 24 timesteps (reward: -1)\n",
      "Finished episode 45 after 24 timesteps (reward: -1)\n",
      "Finished episode 46 after 24 timesteps (reward: -1)\n",
      "Finished episode 47 after 24 timesteps (reward: -1)\n",
      "Finished episode 48 after 24 timesteps (reward: -1)\n",
      "Finished episode 49 after 24 timesteps (reward: -1)\n",
      "Finished episode 50 after 24 timesteps (reward: -1)\n",
      "Finished episode 51 after 24 timesteps (reward: -1)\n",
      "Finished episode 52 after 24 timesteps (reward: -1)\n",
      "Finished episode 53 after 24 timesteps (reward: -1)\n",
      "Finished episode 54 after 24 timesteps (reward: -1)\n",
      "Finished episode 55 after 24 timesteps (reward: -1)\n",
      "Finished episode 56 after 24 timesteps (reward: -1)\n",
      "Finished episode 57 after 24 timesteps (reward: -1)\n",
      "Finished episode 58 after 24 timesteps (reward: -1)\n",
      "Finished episode 59 after 24 timesteps (reward: -1)\n",
      "Finished episode 60 after 24 timesteps (reward: -1)\n",
      "Finished episode 61 after 24 timesteps (reward: -1)\n",
      "Finished episode 62 after 24 timesteps (reward: -1)\n",
      "Finished episode 63 after 24 timesteps (reward: -1)\n",
      "Finished episode 64 after 24 timesteps (reward: -1)\n",
      "Finished episode 65 after 24 timesteps (reward: -1)\n",
      "Finished episode 66 after 24 timesteps (reward: -1)\n",
      "Finished episode 67 after 24 timesteps (reward: -1)\n",
      "Finished episode 68 after 24 timesteps (reward: -1)\n",
      "Finished episode 69 after 24 timesteps (reward: -1)\n",
      "Finished episode 70 after 24 timesteps (reward: -1)\n",
      "Finished episode 71 after 24 timesteps (reward: -1)\n",
      "Finished episode 72 after 24 timesteps (reward: -1)\n",
      "Finished episode 73 after 24 timesteps (reward: -1)\n",
      "Finished episode 74 after 24 timesteps (reward: -1)\n",
      "Finished episode 75 after 24 timesteps (reward: -1)\n",
      "Finished episode 76 after 24 timesteps (reward: -1)\n",
      "Finished episode 77 after 24 timesteps (reward: -1)\n",
      "Finished episode 78 after 24 timesteps (reward: -1)\n",
      "Finished episode 79 after 24 timesteps (reward: -1)\n",
      "Finished episode 80 after 24 timesteps (reward: -1)\n",
      "Finished episode 81 after 24 timesteps (reward: -1)\n",
      "Finished episode 82 after 24 timesteps (reward: -1)\n",
      "Finished episode 83 after 24 timesteps (reward: -1)\n",
      "Finished episode 84 after 24 timesteps (reward: -1)\n",
      "Finished episode 85 after 24 timesteps (reward: -1)\n",
      "Finished episode 86 after 24 timesteps (reward: -1)\n",
      "Finished episode 87 after 24 timesteps (reward: -1)\n",
      "Finished episode 88 after 24 timesteps (reward: -1)\n",
      "Finished episode 89 after 24 timesteps (reward: -1)\n",
      "Finished episode 90 after 24 timesteps (reward: -1)\n",
      "Finished episode 91 after 24 timesteps (reward: -1)\n",
      "Finished episode 92 after 24 timesteps (reward: -1)\n",
      "Finished episode 93 after 24 timesteps (reward: -1)\n",
      "Finished episode 94 after 24 timesteps (reward: -1)\n",
      "Finished episode 95 after 24 timesteps (reward: -1)\n",
      "Finished episode 96 after 24 timesteps (reward: -1)\n",
      "Finished episode 97 after 24 timesteps (reward: -1)\n",
      "Finished episode 98 after 24 timesteps (reward: -1)\n",
      "Finished episode 99 after 24 timesteps (reward: -1)\n",
      "Finished episode 100 after 24 timesteps (reward: -1)\n",
      "Learning finished. Total episodes: 100. Average reward of last 100 episodes: -1.0.\n"
     ]
    }
   ],
   "source": [
    "# Start learning\n",
    "runner.run(episodes=100, max_episode_timesteps=200, episode_finished=episode_finished)\n",
    " \n",
    "# Print statistics\n",
    "print(\"Learning finished. Total episodes: {ep}. Average reward of last 100 episodes: {ar}.\".format(\n",
    "    ep=runner.episode,\n",
    "    ar=np.mean(runner.episode_rewards[-100:]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = [\n",
    "    0,1,1,\n",
    "    1,0,1,\n",
    "    2,1,0,\n",
    "    1,1,1,\n",
    "    20\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
